---
title: "simultaneous_ci_dev"
output: html_document
date: "2025-10-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(9999)
if(!require('pacman')) {
  install.packages('pacman')
}
pacman::p_load(gamlss, dplyr, ggplot2, gamlssTools, mgcv)
```

Attempting to develop simultaneous CIs for GAMLSS smooths. Working from Gavin Simpson's post at https://fromthebottomoftheheap.net/2016/12/15/simultaneous-interval-revisited/

```{r}
rmvn <- function(n, mu, sig) { ## MVN random deviates
    L <- mgcv::mroot(sig)
    m <- ncol(L)
    t(mu + L %*% matrix(rnorm(m*n), m, n))
}
```

First, run through with `mgcv`

```{r}
N <- 10 #reps
gam <- gam(Sepal.Width ~ s(Sepal.Length, k = 20), data = iris, method = "REML")
Vb <- vcov(gam)
newd <- with(iris, data.frame(Sepal.Length = seq(min(Sepal.Length), max(Sepal.Length), length = 200)))
pred <- predict(gam, newd, se.fit = TRUE)
se.fit <- pred$se.fit #standard errors at each point along x

BUdiff <- rmvn(N, mu = rep(0, nrow(Vb)), sig = Vb) #distribution of errors(?) at each basis fun for each simulation
```

```{r}
Cg <- predict(gam, newd, type = "lpmatrix") #linear predictors across x for each basis fun
simDev <- Cg %*% t(BUdiff)

absDev <- abs(sweep(simDev, 1, se.fit, FUN = "/")) #abs(pred-true/se) at each point along x for each sim

masd <- apply(absDev, 2L, max) #max abs std dev across x for each sim

crit <- quantile(masd, prob = 0.95, type = 8)
```


```{r}
iris_model <- gamlss(formula = Sepal.Width ~ pb(Sepal.Length) + Species, sigma.formula = ~ Sepal.Length, data=iris)
```

first, try getting covariance matrix

```{r}

Vb <- rvcov(iris_model) #covariance matrix robust - idk if this is valid though
BUdiff <- rmvn(N, mu = rep(0, nrow(Vb)), sig = Vb)
```

attempt getting Cg
```{r}
#Cg <- predict(m, newd, type = "lpmatrix")
new_data <- sim_data(iris, "Sepal.Length")$df
Cg <- predictAll(iris_model, newdata=new_data, data=iris, output="matrix")

#trying to just play around with mu for now

```



playing around with code from https://github.com/xingaostat/Nonparametric-simultaneous-intervals/blob/main/heartjune212021_github.txt
https://www.mdpi.com/2073-8994/13/7/1212#B5-symmetry-13-01212

1. Generate B bootstrap samples ğ‘ğ‘,ğ‘=1,â€¦,ğµ, by sampling with replacement and obtain the bootstrap estimates ğœƒÌƒğ‘={ğœƒÌƒğ‘1,â€¦,ğœƒÌƒğ‘ğ‘}

```{r}
#bootstap
boot_mods <- bootstrap_gamlss(iris_model, df=iris, B=30,  type="resample", stratify=TRUE, group_var="Species")

#get 50th centile for each bootstrap
sim_data_list <- sim_data(iris, "Sepal.Length", "Species")
cent_boot_list <- lapply(boot_mods,
                         centile_predict,
                         sim_df_list = sim_data_list,
                         x_var="Sepal.Length", 
                         desiredCentiles=0.5)
```


2. For each coordinate j, ğ‘—=1,â€¦,ğ‘, order the bootstrap estimates as ğœƒÌƒ(1ğ‘—)â‰¤ğœƒÌƒ(2ğ‘—)â‰¤â‹¯â‰¤ğœƒÌƒ(ğµğ‘—).
In the case of tied observation, we use random ranks. The rank of ğœƒÌƒğ‘ğ‘— is denoted as ğ‘Ÿ(ğ‘,ğ‘—).
For each sample, find the maximum rank ğ‘Ÿ(ğ‘)=maxğ‘—ğ‘Ÿ(ğ‘,ğ‘—), which is the largest rank associated with the bth bootstrap sample.

```{r}
#rank each predicted value at each x
cent_boot_dfs <- cent_boot_list %>% 
  purrr:::transpose() %>%
  purrr:::map(bind_rows, .id="boot")

boot_ranks <- function(df, xvar, f){
  f <- match.fun(f)

  df %>%
    #group at each x
    arrange(!!sym(xvar)) %>%
    mutate(x_bin = cut(!!sym(xvar), breaks = 500)) %>%
    group_by(x_bin) %>%
    #at each x, rank boot by cent_0.5
    mutate(rank = frank(cent_0.5, ties.method = "random")) %>%
    ungroup() %>%
    #find each bootstrap's biggest rank across x
    group_by(boot) %>%
    summarise(
      rank_stat = f(rank),
      .groups="keep"
    )
}

max_ranks <- lapply(cent_boot_dfs,
                    boot_ranks,
                    xvar="Sepal.Length",
                    f="max")
```

3. Calculate the (1âˆ’ğ›¼/2) percentile ğ‘Ÿ1âˆ’ğ›¼/2 of ğ‘Ÿ(ğ‘).

```{r}
#what's the 97.5th percentile of max ranks
filt_rank_pct <- function(df, pct, keep=c("less", "greater")){
  stopifnot(pct > 0 && pct < 1)
  cutoff <- quantile(df$rank_stat, probs=pct)
  
  pct_pretty <- pct*100

  keep <- match.arg(keep)
  if(keep == "less"){
    print(paste0("keep ranks less than or = ", cutoff, " (", pct_pretty, "%)"))
    df <- df %>%
      filter(rank_stat <= cutoff)
  } else if(keep == "greater"){
    print(paste0("keep ranks greater than or = ", cutoff, " (", pct_pretty, "%)"))
    df <- df %>%
      filter(rank_stat >= cutoff)
  }
  return(df)
}

max_ranks_pct <- lapply(max_ranks,
                        filt_rank_pct,
                        pct=0.975,
                        keep="less")
```

4. Denote the collection of bootstrap samples with the maximum sample rank equal or below the ğ‘Ÿ1âˆ’ğ›¼/2 as Î¦, i.e., ğ‘âˆˆÎ¦ if ğ‘Ÿ(ğ‘)â‰¤ğ‘Ÿ1âˆ’ğ›¼/2.

```{r}
#get the bootstraps who's max rank is <= 97.5th %
phi_boot_dfs <- lapply(seq_along(cent_boot_dfs), function(i){
  df <- cent_boot_dfs[[i]]
  keep_list <- max_ranks_pct[[i]]
  
 df <- df %>%
   filter(boot %in% keep_list$boot)
})
```

5. For each coordinate j, order the bootstrap estimates in set Î¦. The new rank of ğœƒÌƒğ‘ğ‘—in set Î¦ is denoted as ğ‘Ÿâ€²(ğ‘,ğ‘—).
For each sample, find the minimum sample rank ğ‘Ÿâ€²(ğ‘)=minğ‘—ğ‘Ÿâ€²(ğ‘,ğ‘—) which is the smallest rank associated with the bth bootstrap sample in set Î¦.

```{r}
#at each point along x, rank the remaining boostraps again, and this time find each bootstrap's minimum rank
min_ranks <- lapply(phi_boot_dfs,
                    boot_ranks,
                    xvar="Sepal.Length",
                    f="min")
```

6. Calculate the ğ›¼/(2âˆ’ğ›¼) percentile the ğ‘Ÿâ€²ğ›¼/(2âˆ’ğ›¼) of ğ‘Ÿâ€²(ğ‘).
Note - i am a little confused that we seem to be calculating percentiles after dropping a certain number of bootstrap samples?

```{r}
#what's the 2.5% of minimum ranks
min_ranks_pct <- lapply(min_ranks,
                        filt_rank_pct,
                        pct=0.025,
                        keep="greater")
```

7. Denote the collection of bootstrap samples within Î¦ with the minimum sample rank above ğ‘Ÿâ€²ğ›¼/(2âˆ’ğ›¼) as Î¨={ğ‘âˆˆÎ¦âˆ£ğ‘Ÿâ€²(ğ‘)â‰¥ğ‘Ÿâ€²ğ›¼/(2âˆ’ğ›¼)}.
```{r}
#keep bootstraps with min ranks >= 2.5%
final_boot_dfs <- lapply(seq_along(phi_boot_dfs), function(i){
  df <- phi_boot_dfs[[i]]
  keep_list <- min_ranks_pct[[i]]
  
 df <- df %>%
   filter(boot %in% keep_list$boot)
})
```

8. To construct the upper and lower limits for each coordinate, calculate ğ‘¡ğ‘—=maxğ‘âˆˆÎ¨ğ‘Ÿ(ğ‘,ğ‘—), and ğ‘¤ğ‘—=minğ‘âˆˆÎ¨ğ‘Ÿ(ğ‘,ğ‘—).
The simultaneous confidence interval upper limits are ğœƒÌƒ(ğ‘¡ğ‘—ğ‘—) and the lower limits are ğœƒÌƒ(ğ‘¤ğ‘—ğ‘—), ğ‘—=1,â€¦,ğ‘, respectively.

```{r}
#at each point along x, get the max and min ranked bootstraps left
ci_list <- lapply(final_boot_dfs, function(df, xvar="Sepal.Length"){
  df <- df %>%
  #group at each x
  arrange(!!sym(xvar)) %>%
  mutate(x_bin = cut(!!sym(xvar), breaks = 500)) %>%
  group_by(x_bin) %>%
  #calculate their y values
  summarise(
          lower := min(cent_0.5),
          upper := max(cent_0.5),
          !!sym(xvar) := mean(!!sym(xvar)),
          .groups = "drop"
        )
} )

#those are your CIs!
```