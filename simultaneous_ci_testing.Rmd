---
title: "simultaneous_ci_dev"
output: html_document
date: "2025-10-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(9999)
if(!require('pacman')) {
  install.packages('pacman')
}
pacman::p_load(gamlss, dplyr, ggplot2, gamlssTools, mgcv)
```

Attempting to develop simultaneous CIs for GAMLSS smooths. Working from Gavin Simpson's post at https://fromthebottomoftheheap.net/2016/12/15/simultaneous-interval-revisited/

```{r}
rmvn <- function(n, mu, sig) { ## MVN random deviates
    L <- mgcv::mroot(sig)
    m <- ncol(L)
    t(mu + L %*% matrix(rnorm(m*n), m, n))
}
```

First, run through with `mgcv`

```{r}
N <- 10 #reps
gam <- gam(Sepal.Width ~ s(Sepal.Length, k = 20), data = iris, method = "REML")
Vb <- vcov(gam)
newd <- with(iris, data.frame(Sepal.Length = seq(min(Sepal.Length), max(Sepal.Length), length = 200)))
pred <- predict(gam, newd, se.fit = TRUE)
se.fit <- pred$se.fit #standard errors at each point along x

BUdiff <- rmvn(N, mu = rep(0, nrow(Vb)), sig = Vb) #distribution of errors(?) at each basis fun for each simulation
```

```{r}
Cg <- predict(gam, newd, type = "lpmatrix") #linear predictors across x for each basis fun
simDev <- Cg %*% t(BUdiff)

absDev <- abs(sweep(simDev, 1, se.fit, FUN = "/")) #abs(pred-true/se) at each point along x for each sim

masd <- apply(absDev, 2L, max) #max abs std dev across x for each sim

crit <- quantile(masd, prob = 0.95, type = 8)
```


```{r}
iris_model <- gamlss(formula = Sepal.Width ~ pb(Sepal.Length) + Species, sigma.formula = ~ Sepal.Length, data=iris)
```

first, try getting covariance matrix

```{r}

Vb <- rvcov(iris_model) #covariance matrix robust - idk if this is valid though
BUdiff <- rmvn(N, mu = rep(0, nrow(Vb)), sig = Vb)
```

attempt getting Cg
```{r}
#Cg <- predict(m, newd, type = "lpmatrix")
new_data <- sim_data(iris, "Sepal.Length")$df
Cg <- predictAll(iris_model, newdata=new_data, data=iris, output="matrix")

#trying to just play around with mu for now

```



playing around with code from https://github.com/xingaostat/Nonparametric-simultaneous-intervals/blob/main/heartjune212021_github.txt
https://www.mdpi.com/2073-8994/13/7/1212#B5-symmetry-13-01212

1. Generate B bootstrap samples 𝑍𝑏,𝑏=1,…,𝐵, by sampling with replacement and obtain the bootstrap estimates 𝜃̃𝑏={𝜃̃𝑏1,…,𝜃̃𝑏𝑝}

```{r}
#bootstap
boot_mods <- bootstrap_gamlss(iris_model, df=iris, B=30,  type="resample", stratify=TRUE, group_var="Species")

#get 50th centile for each bootstrap
sim_data_list <- sim_data(iris, "Sepal.Length", "Species")
cent_boot_list <- lapply(boot_mods,
                         centile_predict,
                         sim_df_list = sim_data_list,
                         x_var="Sepal.Length", 
                         desiredCentiles=0.5)
```


2. For each coordinate j, 𝑗=1,…,𝑝, order the bootstrap estimates as 𝜃̃(1𝑗)≤𝜃̃(2𝑗)≤⋯≤𝜃̃(𝐵𝑗).
In the case of tied observation, we use random ranks. The rank of 𝜃̃𝑏𝑗 is denoted as 𝑟(𝑏,𝑗).
For each sample, find the maximum rank 𝑟(𝑏)=max𝑗𝑟(𝑏,𝑗), which is the largest rank associated with the bth bootstrap sample.

```{r}
#rank each predicted value at each x
cent_boot_dfs <- cent_boot_list %>% 
  purrr:::transpose() %>%
  purrr:::map(bind_rows, .id="boot")

boot_ranks <- function(df, xvar, f){
  f <- match.fun(f)

  df %>%
    #group at each x
    arrange(!!sym(xvar)) %>%
    mutate(x_bin = cut(!!sym(xvar), breaks = 500)) %>%
    group_by(x_bin) %>%
    #at each x, rank boot by cent_0.5
    mutate(rank = frank(cent_0.5, ties.method = "random")) %>%
    ungroup() %>%
    #find each bootstrap's biggest rank across x
    group_by(boot) %>%
    summarise(
      rank_stat = f(rank),
      .groups="keep"
    )
}

max_ranks <- lapply(cent_boot_dfs,
                    boot_ranks,
                    xvar="Sepal.Length",
                    f="max")
```

3. Calculate the (1−𝛼/2) percentile 𝑟1−𝛼/2 of 𝑟(𝑏).

```{r}
#what's the 97.5th percentile of max ranks
filt_rank_pct <- function(df, pct, keep=c("less", "greater")){
  stopifnot(pct > 0 && pct < 1)
  cutoff <- quantile(df$rank_stat, probs=pct)
  
  pct_pretty <- pct*100

  keep <- match.arg(keep)
  if(keep == "less"){
    print(paste0("keep ranks less than or = ", cutoff, " (", pct_pretty, "%)"))
    df <- df %>%
      filter(rank_stat <= cutoff)
  } else if(keep == "greater"){
    print(paste0("keep ranks greater than or = ", cutoff, " (", pct_pretty, "%)"))
    df <- df %>%
      filter(rank_stat >= cutoff)
  }
  return(df)
}

max_ranks_pct <- lapply(max_ranks,
                        filt_rank_pct,
                        pct=0.975,
                        keep="less")
```

4. Denote the collection of bootstrap samples with the maximum sample rank equal or below the 𝑟1−𝛼/2 as Φ, i.e., 𝑏∈Φ if 𝑟(𝑏)≤𝑟1−𝛼/2.

```{r}
#get the bootstraps who's max rank is <= 97.5th %
phi_boot_dfs <- lapply(seq_along(cent_boot_dfs), function(i){
  df <- cent_boot_dfs[[i]]
  keep_list <- max_ranks_pct[[i]]
  
 df <- df %>%
   filter(boot %in% keep_list$boot)
})
```

5. For each coordinate j, order the bootstrap estimates in set Φ. The new rank of 𝜃̃𝑏𝑗in set Φ is denoted as 𝑟′(𝑏,𝑗).
For each sample, find the minimum sample rank 𝑟′(𝑏)=min𝑗𝑟′(𝑏,𝑗) which is the smallest rank associated with the bth bootstrap sample in set Φ.

```{r}
#at each point along x, rank the remaining boostraps again, and this time find each bootstrap's minimum rank
min_ranks <- lapply(phi_boot_dfs,
                    boot_ranks,
                    xvar="Sepal.Length",
                    f="min")
```

6. Calculate the 𝛼/(2−𝛼) percentile the 𝑟′𝛼/(2−𝛼) of 𝑟′(𝑏).
Note - i am a little confused that we seem to be calculating percentiles after dropping a certain number of bootstrap samples?

```{r}
#what's the 2.5% of minimum ranks
min_ranks_pct <- lapply(min_ranks,
                        filt_rank_pct,
                        pct=0.025,
                        keep="greater")
```

7. Denote the collection of bootstrap samples within Φ with the minimum sample rank above 𝑟′𝛼/(2−𝛼) as Ψ={𝑏∈Φ∣𝑟′(𝑏)≥𝑟′𝛼/(2−𝛼)}.
```{r}
#keep bootstraps with min ranks >= 2.5%
final_boot_dfs <- lapply(seq_along(phi_boot_dfs), function(i){
  df <- phi_boot_dfs[[i]]
  keep_list <- min_ranks_pct[[i]]
  
 df <- df %>%
   filter(boot %in% keep_list$boot)
})
```

8. To construct the upper and lower limits for each coordinate, calculate 𝑡𝑗=max𝑏∈Ψ𝑟(𝑏,𝑗), and 𝑤𝑗=min𝑏∈Ψ𝑟(𝑏,𝑗).
The simultaneous confidence interval upper limits are 𝜃̃(𝑡𝑗𝑗) and the lower limits are 𝜃̃(𝑤𝑗𝑗), 𝑗=1,…,𝑝, respectively.

```{r}
#at each point along x, get the max and min ranked bootstraps left
ci_list <- lapply(final_boot_dfs, function(df, xvar="Sepal.Length"){
  df <- df %>%
  #group at each x
  arrange(!!sym(xvar)) %>%
  mutate(x_bin = cut(!!sym(xvar), breaks = 500)) %>%
  group_by(x_bin) %>%
  #calculate their y values
  summarise(
          lower := min(cent_0.5),
          upper := max(cent_0.5),
          !!sym(xvar) := mean(!!sym(xvar)),
          .groups = "drop"
        )
} )

#those are your CIs!
```